{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Classification \n",
    "\n",
    "## Introduction\n",
    "\n",
    "<img align=\"right\" width=\"175\" height=\"175\" src=\"./figures/stressful.png\"> Spam classification has been a widely studied NLP task. In our daily life, one's personal definition for spam emails could be very different. Like many others I have a Gmail account that I use for registration or subscription to websites or feeds. Over time it has accumulated tons of emails including ads and trivial updates that I would hardly skim over. However, buried under this mountain of emails are the actually IMPORTANT ones: personal messages from family and friends, important account records, tax document, medical bills, etc. I have a habit of archiving these emails for future references but over time I am growing tired of manually filtering out and classifying emails. Moreover, scanning through tens of emails each day, one could mistakenly delete important emails without even noticing. This makes me think, if I can build a automatic email filter based on the thousands of previously labeled or classified emails? Furthermore, this filter, if successful, would help me label future emails more consistently which in turn will improve the filter even further.\n",
    "\n",
    "What features may be useful in email classification?\n",
    "1. The subject and the text body are the most informative features in most situations. One could train a classification model directly based on the text, or extract additional features, e.g., BOW, TF-IDF, text length, number of punctuations, that could feed into a classifier.\n",
    "2. Sender(From). Emails from personal accounts and several institutional accounts are more likely to be important than those from big companies. However, there are exceptions, for example, receipts, bills and tax documents should be kept, while trivial weekly updates from the University would normally be discard.\n",
    "3. Recipients(To). Usually emails with 2 - 10 recipients are important, especially if some of the recipients are friends, collaborators, etc.\n",
    "\n",
    "In this notebook I will focus on building a email filter using only the text information (#1 point). This includes training and comparing various classifiers from 6000+ emails from my personal Gmail account. I collected these emails using the Gmail APIs and pre-processed them with various NLP libraries (more details in ). Around 10% of the emails have been labeled as important, based on various criteria. To perform binary classification on these emails, I trained a SVC and a Naive Bayes classifier from the word vectors, as well as two neural networks, a BERT (Bidirectional Encoder Representations from Transformers) model and a BiLSTM (Bidirectional Long Short-Term Memory) model, based on the subjects of the emails.\n",
    "\n",
    "To begin with, I split the email sample into training and test set (80%/20%). Since the dataset is very imbalanced for the binary classification task with less than 10% positive samples (important emails), I upsampled the positive samples so that the positive and negative samples are comparable. Finally I would apply the trained model on the test set to evaluate the precision/recall of the classifier.\n",
    "\n",
    "Training on an imbalanced dataset may yield disastrous results. For example, in this email classification task, without up-sampling the BiLSTM model may tend to predict every single email as unimportant, i.e., >90% accuracy but 0% recall. My experiments also show that the SVC is quite robust to imbalanced dataset while the Naive Bayes classifier is not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Dataset\n",
    "\n",
    "### Labeling\n",
    "\n",
    "Using the Gmail API ([code](https://github.com/shuiyao/gmail_helper/blob/main/gmail.py)), I collected a total of 6000+ emails from my personal account. Firstly, I labeled all emails from my personal sub-folders as *important* and labeled the rest of the emails in the INBOX folder as *unimportant*. The reason is that I personally tend to manually categorize important emails and move them to a named sub-folder for keeping. However, this is by no means a very accurate way of labeling emails, as I sometimes forgot or simply was lazy to archive every single email that is considered important. For example, I used to keep every ATT bill in a separate folder but later discarded this habit. This could potentially confuse the classifier.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "To make things easier, first I remove all emails that are composed in Chinese:\n",
    "\n",
    "```python\n",
    "from langdetect import DetectorFactory, detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def is_eng(text):\n",
    "    try:\n",
    "        if detect(text) == 'zh-cn':\n",
    "            return False\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df = df[df['subject'].apply(is_eng)]\n",
    "```\n",
    "\n",
    "Next, I pre-processed the email body text. \n",
    "Some key steps specific to the email dataset are:\n",
    "- Remove URLs. URLs are prevalent in emails, but the tokenizer often doesn't handle them well.\n",
    "- Remove fragments of meaningless text. The email body text was converted from the html and often has uncleaned relics of html syntaxs. Therefore, I select only tokens that appear in one of the two NLTK corpus.\n",
    "\n",
    "```python\n",
    "import spacy\n",
    "import string\n",
    "from nltk import stopwords\n",
    "\n",
    "def rm_punc_from_word(word):\n",
    "    return ''.join([c for c in word if c not in string.punctuation])\n",
    "\n",
    "stopwords_eng = stopwords.words('english')\n",
    "stopwords_nopunc = set(map(rm_punc_from_word, stopwords.words('english')))\n",
    "\n",
    "class SpacyLemmatizer():\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "        self.postags = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]\n",
    "    def lemmatize(self, words):\n",
    "        doc = self.nlp(' '.join(words))\n",
    "        return ' '.join([t.lemma_ for t in doc if t.pos_ in self.postags])\n",
    "\n",
    "def clean_text(txt, lemmatizer=None, stemmer=None):\n",
    "    '''\n",
    "    Pre-process on the raw text: remove spurious features, remove punctuations and stop words, lemmatize.\n",
    "    '''\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"https\\S+\", '', txt)\n",
    "\n",
    "    txt = re.sub(r'([a-z])\\1{2,}', r'\\1', txt)\n",
    "    txt = re.sub(r'([\\W+])\\1{1,}', r'\\1', txt)\n",
    "\n",
    "    chars = [c for c in txt if c not in string.punctuation]\n",
    "    txt = ''.join(chars)\n",
    "    words = [wd for wd in txt.split() if wd not in stopwords_nopunc]\n",
    "    txt = ' '.join(words)\n",
    "    if(stemmer is not None):\n",
    "        words = [stemmer.stem() for wd in words]\n",
    "    if(lemmatizer is not None):\n",
    "        txt = lemmatizer.lemmatize(words)\n",
    "    return txt\n",
    "\n",
    "nltk_words = set(nltk.corpus.words.words())\n",
    "web_words = set(nltk.corpus.webtext.words('firefox.txt'))\n",
    "\n",
    "def remove_gibberish(txt):\n",
    "    words = txt.split()\n",
    "    words = [wd for wd in words if wd in nltk_words or wd in web_words]    \n",
    "    txt = ' '.join(words)\n",
    "    return txt\n",
    "```\n",
    "\n",
    "In the end I collected 5632 emails labeled unimportant and 434 emails labeled important, resulting in a very imbalanced dataset. I further separated these emails into a training set and a test set with a 80%/20% splitting.\n",
    "\n",
    "The following code shows the number of positive/negative samples in the train/test set, and display a random sample from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emailfilter\n",
    "ef_svc = emailfilter.EmailFilterSVC()\n",
    "ef_svc.load_data('train.csv', 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4502\n",
      "1     351\n",
      "Name: target, dtype: int64\n",
      "0    1130\n",
      "1      83\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ef_svc.train['target'].value_counts())\n",
    "print(ef_svc.test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sender</th>\n",
       "      <th>labels</th>\n",
       "      <th>body</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>Don't miss out on the final week of new online...</td>\n",
       "      <td>Tanglewood &lt;mybso@bso.org&gt;</td>\n",
       "      <td>CATEGORY_PROMOTIONS, INBOX</td>\n",
       "      <td>experience new performance week musician world...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>⌛ Save up to 20% off Worldwide Car Rentals thi...</td>\n",
       "      <td>Webjet &lt;noreply@webjet.com&gt;</td>\n",
       "      <td>CATEGORY_PROMOTIONS, IMPORTANT, INBOX</td>\n",
       "      <td>shuiyao save time money hassle worldwide car r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>For your August 22 flight: Inflight Wi-Fi and ...</td>\n",
       "      <td>United Airlines &lt;UnitedAirlines@news.united.com&gt;</td>\n",
       "      <td>CATEGORY_PROMOTIONS, IMPORTANT, INBOX</td>\n",
       "      <td>united airline unite mileageplus make next tra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>eTicket Itinerary and Receipt for Confirmation...</td>\n",
       "      <td>\"United Airlines, Inc. \" &lt;unitedairlines@unite...</td>\n",
       "      <td>IMPORTANT, INBOX/TRAVEL, CATEGORY_UPDATES</td>\n",
       "      <td>eticket itinerary receipt receipt confirmation...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>A Special Message from Maestro Kevin Rhodes!</td>\n",
       "      <td>Springfield Symphony Orchestra &lt;info@springfie...</td>\n",
       "      <td>CATEGORY_PROMOTIONS, IMPORTANT, INBOX</td>\n",
       "      <td>dear friend sso hope join year meet musician e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                subject  \\\n",
       "4106  Don't miss out on the final week of new online...   \n",
       "4042  ⌛ Save up to 20% off Worldwide Car Rentals thi...   \n",
       "1571  For your August 22 flight: Inflight Wi-Fi and ...   \n",
       "847   eTicket Itinerary and Receipt for Confirmation...   \n",
       "3154       A Special Message from Maestro Kevin Rhodes!   \n",
       "\n",
       "                                                 sender  \\\n",
       "4106                         Tanglewood <mybso@bso.org>   \n",
       "4042                        Webjet <noreply@webjet.com>   \n",
       "1571   United Airlines <UnitedAirlines@news.united.com>   \n",
       "847   \"United Airlines, Inc. \" <unitedairlines@unite...   \n",
       "3154  Springfield Symphony Orchestra <info@springfie...   \n",
       "\n",
       "                                         labels  \\\n",
       "4106                 CATEGORY_PROMOTIONS, INBOX   \n",
       "4042      CATEGORY_PROMOTIONS, IMPORTANT, INBOX   \n",
       "1571      CATEGORY_PROMOTIONS, IMPORTANT, INBOX   \n",
       "847   IMPORTANT, INBOX/TRAVEL, CATEGORY_UPDATES   \n",
       "3154      CATEGORY_PROMOTIONS, IMPORTANT, INBOX   \n",
       "\n",
       "                                                   body  target  \n",
       "4106  experience new performance week musician world...       0  \n",
       "4042  shuiyao save time money hassle worldwide car r...       0  \n",
       "1571  united airline unite mileageplus make next tra...       0  \n",
       "847   eticket itinerary receipt receipt confirmation...       1  \n",
       "3154  dear friend sso hope join year meet musician e...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ef_svc.train.sample(n=5, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The classifiers are implemented in [emailfilter.py](https://github.com/shuiyao/gmail_helper/blob/main/emailfilter.py)\n",
    "\n",
    "### Naive Bayes and Support Vector Classifiers\n",
    "\n",
    "Both of these methods are known to have good performance in the spam classification task. Both classifiers train on a selected word vector representation of the text. Commonly used vectorization methods include the bag of words (BOW) and the term frequency - inverse document frequency (Tf-Idf). Here I will use the TfIdfVectorizer() from the sklearn library, though using the CountVectorizer() achieves a similar result for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer(max_features=10000, max_df=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_svc = emailfilter.EmailFilterSVC(C=1.0, vectorizer=vectorizer)\n",
    "ef_nb = emailfilter.EmailFilterBayes(alpha=1.0, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both classifiers can be trained similarly as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.48351648298514677\n",
      "Recall: 0.5301204812890115\n",
      "F1 score: 0.2528735379805811\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ef_svc.load_data('train.csv', 'test.csv')\n",
    "ef_svc.vectorize() # Train the tfidf vectorizer\n",
    "ef_svc.upsample() # Up-sample the minority class\n",
    "ef_svc.fit()\n",
    "_, _ = ef_svc.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples after resampling: 9004\n",
      "Precision: 0.3595505615957581\n",
      "Recall: 0.7710843364203803\n",
      "F1 score: 0.24521070609357068\n"
     ]
    }
   ],
   "source": [
    "ef_nb.load_data('train.csv', 'test.csv')\n",
    "ef_nb.vectorize() # Train the tfidf vectorizer\n",
    "ef_nb.upsample() # Up-sample the minority class\n",
    "ef_nb.fit()\n",
    "_, _ = ef_nb.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM and BERT Classifiers\n",
    "\n",
    "These methods rely on a trained neural network language model with a sigmoid layer attached at the end for binary classification. The BiLSTM used to be the architecture for state-of-art language models. One can initialize the weights in a BiLSTM model with pre-trained word embeddings (e.g., GloVe embeddings) to accelerate the training process. However, in recent years, the BERT model and its variants are often praised as revolutionary in the NLP field, so I decided to also train a BERT classifier to see how it performs on this small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef_bilstm = emailfilter.EmailFilterBiLSTM()\n",
    "ef_bert = emailfilter.EmailFilterBERT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training these models take much longer than the SVC or the Naive Bayes classifier. For the purpose of demonstration, I trained these models on the subject sentence instead of the entire email body.\n",
    "\n",
    "```python\n",
    "# User-defined Loss functions and Optimizers\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "# metrics = ['accuracy'] \n",
    "\n",
    "# BiLSTM + GloVe embeddings\n",
    "params_bilstm = {'epochs':20, 'batch_size':32, 'validation_steps':10}\n",
    "ef_bilstm.load_data('train.csv','test.csv')\n",
    "ef_bilstm.build_model()\n",
    "ef_bilstm.upsample()\n",
    "ef_bilstm.compile(loss=loss, optimizer=optimizer)\n",
    "ef_bilstm.fit(**params_bilstm)\n",
    "ef_bilstm.evaluate()\n",
    "\n",
    "# BERT\n",
    "params_bert = {'epochs':5, 'batch_size':32, 'validation_steps':10}\n",
    "ef_bert.load_data('train.csv','test.csv')\n",
    "ef_bert.upsample()\n",
    "# efilter.load_model('model_bert_epoch5.h5') # optionally, one can load saved model\n",
    "ef_bert.compile(loss=loss, optimizer=optimizer)\n",
    "ef_bert.fit(**params_bert)\n",
    "ef_bert.evaluate(return_false_samples=True)\n",
    "```\n",
    "\n",
    "I trained the BiLSTM model for 20 epochs and the BERT model for 5 epochs. The BERT model trains much slower but also converges much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log from the BiLSTM model:\n",
    "\n",
    "```\n",
    "Epoch 1/20\n",
    "231/231 [==============================] - 14s 36ms/step - loss: 0.6881 - accuracy: 0.5941 - tp: 704.2543 - fn: 1171.5388 - preci: 0.6878 - recal: 0.3704 - val_loss: 0.6049 - val_accuracy: 0.7688 - val_tp: 104.0000 - val_fn: 56.0000 - val_preci: 0.8525 - val_recal: 0.6500\n",
    "Epoch 2/20\n",
    "231/231 [==============================] - 6s 25ms/step - loss: 0.5236 - accuracy: 0.8208 - tp: 1583.9526 - fn: 284.1638 - preci: 0.8197 - recal: 0.8207 - val_loss: 0.3206 - val_accuracy: 0.8781 - val_tp: 147.0000 - val_fn: 13.0000 - val_preci: 0.8497 - val_recal: 0.9187\n",
    "...\n",
    "Epoch 19/20\n",
    "231/231 [==============================] - 6s 27ms/step - loss: 0.1350 - accuracy: 0.9442 - tp: 1819.2629 - fn: 46.4224 - preci: 0.9162 - recal: 0.9772 - val_loss: 0.2031 - val_accuracy: 0.9094 - val_tp: 148.0000 - val_fn: 6.0000 - val_preci: 0.8655 - val_recal: 0.9610\n",
    "Epoch 20/20\n",
    "231/231 [==============================] - 6s 26ms/step - loss: 0.1286 - accuracy: 0.9465 - tp: 1820.4052 - fn: 47.0948 - preci: 0.9207 - recal: 0.9765 - val_loss: 0.1842 - val_accuracy: 0.9281 - val_tp: 153.0000 - val_fn: 2.0000 - val_preci: 0.8793 - val_recal: 0.9871\n",
    "```\n",
    "\n",
    "Log from the BERT model\n",
    "\n",
    "```\n",
    "Epoch 1/5\n",
    "231/231 [==============================] - 1326s 6s/step - loss: 0.3909 - accuracy: 0.8123 - tp: 1607.8664 - fn: 257.4655 - preci: 0.8104 - recal: 0.8131 - val_loss: 0.1316 - val_accuracy: 0.9469 - val_tp: 140.0000 - val_fn: 2.0000 - val_preci: 0.9032 - val_recal: 0.9859\n",
    "Epoch 2/5\n",
    "231/231 [==============================] - 1315s 6s/step - loss: 0.1026 - accuracy: 0.9647 - tp: 1817.7284 - fn: 51.1940 - preci: 0.9572 - recal: 0.9726 - val_loss: 0.1305 - val_accuracy: 0.9438 - val_tp: 152.0000 - val_fn: 6.0000 - val_preci: 0.9268 - val_recal: 0.9620\n",
    "Epoch 3/5\n",
    "231/231 [==============================] - 1314s 6s/step - loss: 0.0675 - accuracy: 0.9755 - tp: 1830.3534 - fn: 41.7414 - preci: 0.9730 - recal: 0.9782 - val_loss: 0.1001 - val_accuracy: 0.9719 - val_tp: 157.0000 - val_fn: 0.0000e+00 - val_preci: 0.9458 - val_recal: 1.0000\n",
    "Epoch 4/5\n",
    "231/231 [==============================] - 1325s 6s/step - loss: 0.0548 - accuracy: 0.9762 - tp: 1834.6638 - fn: 37.4741 - preci: 0.9730 - recal: 0.9796 - val_loss: 0.1244 - val_accuracy: 0.9500 - val_tp: 140.0000 - val_fn: 5.0000 - val_preci: 0.9272 - val_recal: 0.9655\n",
    "Epoch 5/5\n",
    "231/231 [==============================] - 1336s 6s/step - loss: 0.0644 - accuracy: 0.9733 - tp: 1833.1379 - fn: 42.1810 - preci: 0.9710 - recal: 0.9762 - val_loss: 0.0983 - val_accuracy: 0.9594 - val_tp: 141.0000 - val_fn: 8.0000 - val_preci: 0.9658 - val_recal: 0.9463\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test scores for the BiLSTM and the BERT classifers are:\n",
    "\n",
    "BiLSTM:\n",
    "```\n",
    "Precision: 0.3540372668608464\n",
    "Recall: 0.6867469871244013\n",
    "F1 score: 0.23360653474032733\n",
    "```\n",
    "\n",
    "BERT:\n",
    "```\n",
    "Precision: 0.43902438988697207\n",
    "Recall: 0.6506024088546959\n",
    "F1 score: 0.2621358980181943\n",
    "```\n",
    "\n",
    "The ROC curves are also similar between these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_bilstm = pd.read_csv('roc_bilstm_epoch20.csv')\n",
    "roc_bert = pd.read_csv('roc_bert_epoch5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc9ccdef880>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(roc_bilstm.FP, roc_bilstm.TP, \"b-\")\n",
    "plt.plot(roc_bert.FP, roc_bert.TP, \"r-\")\n",
    "plt.xlabel(\"TP\")\n",
    "plt.ylabel(\"FP\")\n",
    "plt.legend(['BiLSTM','BERT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at the emails that are classified incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_fp = pd.read_csv(\"bert_false_positive.csv\")\n",
    "bert_fn = pd.read_csv(\"bert_false_negative.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the \"false positives\" (incorrectly predicted as important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plymouth Rock policy PRA00002003913* Huang</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We approved your application</td>\n",
       "      <td>0</td>\n",
       "      <td>0.980728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fwd: We've saved your application</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fwd: by-law</td>\n",
       "      <td>0</td>\n",
       "      <td>0.949142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Your recent Dental Claim is ready for review</td>\n",
       "      <td>0</td>\n",
       "      <td>0.807456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Airport check-in required for confirmation P0E0WV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Re: Make Schengen appointment [#1553]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re: Make Schengen appointment [#1553]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Re: Make Schengen appointment [#1553]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  target      pred\n",
       "1         Plymouth Rock policy PRA00002003913* Huang       0  0.982334\n",
       "2                       We approved your application       0  0.980728\n",
       "3                  Fwd: We've saved your application       0  0.997871\n",
       "4                                        Fwd: by-law       0  0.949142\n",
       "5       Your recent Dental Claim is ready for review       0  0.807456\n",
       "6  Airport check-in required for confirmation P0E0WV       0  0.815866\n",
       "7              Re: Make Schengen appointment [#1553]       0  0.947283\n",
       "8              Re: Make Schengen appointment [#1553]       0  0.947283\n",
       "9              Re: Make Schengen appointment [#1553]       0  0.947283"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_fp[['subject','target','pred']].iloc[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, in fact some of them should be labeled as important emails so at least some of the mis-classifications are actually due to mis-labeling. Another finding is that the classifier indentifies many of the *replied* and *forwarded* emails as important, while I usually only keep the first email in the thread stored. Like the examples shown here, many of the false positives are not due to the machine learning algorithms.\n",
    "\n",
    "Then the false negatives (important emails that are missed by the classifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paperless enrollment confirmation</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Order ID: ORD20188453592606 From www.CallingCa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.338039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PO Number: ORD20188453592606 from www.CallingC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.088176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Your JetPens Order Has Shipped! (337681)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Your JetPens Order (337681)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AT&amp;T payment update</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WMECO E-Bill Ready For Viewing (72821705)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stellar Physics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  target      pred\n",
       "1                  Paperless enrollment confirmation       1  0.000126\n",
       "2  Order ID: ORD20188453592606 From www.CallingCa...       1  0.338039\n",
       "3  PO Number: ORD20188453592606 from www.CallingC...       1  0.088176\n",
       "4           Your JetPens Order Has Shipped! (337681)       1  0.000093\n",
       "5                        Your JetPens Order (337681)       1  0.002366\n",
       "6                                                NaN       1  0.000626\n",
       "7                                AT&T payment update       1  0.185311\n",
       "8          WMECO E-Bill Ready For Viewing (72821705)       1  0.415885\n",
       "9                                    Stellar Physics       1  0.002143"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_fn[['subject','target','pred']].iloc[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the misses here are also due to mis-labeling. For example, of the many emails with a subject like \"Your ... Order ... Shipped\", only a few is labeled as important. The labeling lacks consistency and therefore the classifier as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take-aways\n",
    "\n",
    "I started out with 6000+ labeled emails from my personal Gmail account, hoping to train a binary classification model that automatically filter out important emails for me. I have used 4 different methods that are popular in spam classification applications, a Naive Bayes and a Support Vector classifier trained on Tf-Idf feature vectors from email bodies, and a BiLSTM and a BERT network trained on the email subjects. All four methods achieve similar precision/recall scores on a same test set, although the BERT model is significantly slower to train.\n",
    "\n",
    "Upsampling the minority class (important emails) proves crucial to the Naive Bayes and the BiLSTM model. But the SVC and the BERT model are less sensitive to it.\n",
    "\n",
    "The classifiers typically get a precision of 40% and a recall of 60%, a result that is much poorer than a typical spam classifier. However, there are several key areas of improvements:\n",
    "1. **Inaccurate labels.** The labels of the email sample are inaccurate. For example, some emails, even though almost identical, are labeled inconsistently. I label an email as important or unimportant simply based on whether or not I have manually categorized it into a sub-folder, which I did before I started with the project. Therefore, it may worth re-labeling the emails in a more systematic and consistent way.\n",
    "2. **Insufficient training data.** The sample size, 6000, is quite small especially for the neural network models. In fact both the BiLSTM and the BERT model had pretty good scores on the training data but do not fit the test data well. \n",
    "3. **Additional features.** The current model relies exclusively on the subject and body text, but one might come up with other features as described in the introduction.\n",
    "4. **Preprocessing steps.** I have not got time to extensively try out different preprocessing methods.\n",
    "\n",
    "Therefore, here are several actions considered for future works:\n",
    "1. Explore the labeled Enron dataset (0.5 million emails) and:\n",
    "  - Gain insights from these emails on extracting additional features that may be important\n",
    "  - Manually select emails from different categories and label them for training\n",
    "  - Improve pre-processing pipelines and fine tune the models with this much larger dataset\n",
    "2. Train a higher level classifier leveraging additional features.\n",
    "3. Deploy and integrate the classifier to guide email filtering for future incoming emails.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
